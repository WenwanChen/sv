# Generated 2023-09-25 from:
# /home/wc43/speechbrain/recipes/IEMOCAP/emotion_recognition/hparams/26_cyclic.yaml
# yamllint disable
# ########################################
# Emotion recognition from speech using wav2vec2
# For more wav2vec2/HuBERT results, please see https://arxiv.org/pdf/2111.02735.pdf
#  * Authors: Yingzhi WANG
# ########################################

# Seed needs to be set at top of yaml, before objects with parameters are made
seed: 1926
__set_seed: !apply:torch.manual_seed [1926]


output_folder: /scratch/wc43/results/vox/1926
save_folder: /scratch/wc43/results/vox/1926/save_sm2_test
train_log: /scratch/wc43/results/vox/1926/train_log_sm2_test.txt


pretrained_path: speechbrain/spkrec-ecapa-voxceleb

# different speakers for train, valid and test sets
# (more challenging exercise: higher error rate)
different_speakers: false

# # Path where data manifest files will be stored
train_annotation: /scratch/wc43/datasets/flac_json/vox_train.json
valid_annotation: /scratch/wc43/datasets/flac_json/vox_valid.json
test_annotation: /scratch/wc43/datasets/flac_json/flac4_bishal_ovl.json
# enroll_enroll_bishal_less.json

# The train logger writes training statistics to a file, as well as stdout.
train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
  save_file: /scratch/wc43/results/vox/1926/train_log_sm2_test.txt

ckpt_interval_minutes: 15 # save checkpoint every N min


# AAM 的时候 lr必须小
# Training parameters
number_of_epochs: 27
# batch_size: 128
batch_size: 512
lr: 0.00005
base_lr: 0.00001
max_lr: 0.00005
step_size: 23430


#freeze all wav2vec2
freeze_wav2vec2: false
#set to true to freeze the CONV part of the wav2vec2 model
# We see an improvement of 2% with freezing CNNs
freeze_wav2vec2_conv: false

# # Model parameters
encoder_dim: 192

# Model parameters
# encoder_dim: 96

# Number of emotions
out_n_neurons: 7246

# 1252 for vox1
# 5995 for vox2
# 6295 for vox2+voices


emb_dim: 512

bn_dim: 256

dataloader_options:
  batch_size: 512
  shuffle: true
  num_workers: 2    # 2 on linux but 0 works on windows
  drop_last: true


avg_pool: !new:speechbrain.nnet.pooling.StatisticsPooling
  return_std: false

asp_pool: &id008 !new:speechbrain.lobes.models.ECAPA_TDNN.AttentiveStatisticsPooling
  channels: 192


output_mlp: &id007 !new:speechbrain.nnet.linear.Linear
  input_size: 192
  n_neurons: 7246
  bias: false

fc1: &id003 !new:speechbrain.nnet.linear.Linear
  input_size: 512
  n_neurons: 512
  bias: false

# Feature parameters
n_mels: 80
left_frames: 0
right_frames: 0
deltas: false


# Functions
compute_features: &id001 !new:speechbrain.lobes.features.Fbank
  n_mels: 80
  left_frames: 0
  right_frames: 0
  deltas: false
mean_var_norm_emb: &id002 !new:speechbrain.processing.features.InputNormalization
  norm_type: sentence
  std_norm: false

fc2: &id004 !new:speechbrain.nnet.linear.Linear
  input_size: 192
  n_neurons: 192
  bias: false

dense1: &id005 !new:speechbrain.nnet.linear.Linear
  input_size: 384
  n_neurons: 512
  bias: false

dense2: &id006 !new:speechbrain.nnet.linear.Linear
  input_size: 512
  n_neurons: 7246
  bias: false

# three fully connected layers with the shape((C + D)//2, bottleneck dim, C)
# D is emb, C is test. C = encoder_dim
drop: !new:speechbrain.nnet.dropout.Dropout2d
  drop_rate: 0.1

bn_fc1: &id009 !new:speechbrain.nnet.linear.Linear
  input_size: 704
  n_neurons: 352
  bias: false

# bn_fc1: !new:speechbrain.nnet.linear.Linear
#     input_size: 608
#     n_neurons: 304
#     bias: False
batchnorm1: &id012 !new:speechbrain.nnet.normalization.BatchNorm1d
  input_size: 352

# batchnorm1: !new:speechbrain.nnet.normalization.BatchNorm1d
#     input_size: 304

bn_fc2: &id010 !new:speechbrain.nnet.linear.Linear
  input_size: 352
  n_neurons: 256
  bias: false

# bn_fc2: !new:speechbrain.nnet.linear.Linear
#     input_size: 304
#     n_neurons: !ref <bn_dim>
#     bias: False
batchnorm2: &id013 !new:speechbrain.nnet.normalization.BatchNorm1d
  input_size: 256

bn_fc3: &id011 !new:speechbrain.nnet.linear.Linear
  input_size: 256
  n_neurons: 192
  bias: false

batchnorm3: &id014 !new:speechbrain.nnet.normalization.BatchNorm1d
#     classifier: !ref <classifier>
#     drop: !ref <drop>



# 需要optimize的部分？
# TypeError: ('Invalid argument to class torch.nn.ModuleList', 'ModuleList.__init__() takes from 1 to 2 positional arguments but 4 were given')
  input_size: 512

batchnorm4: !new:speechbrain.nnet.normalization.BatchNorm1d
  input_size: 512

epoch_counter: &id020 !new:speechbrain.utils.epoch_loop.EpochCounter
  limit: 27

classifier: &id016 !new:speechbrain.lobes.models.ECAPA_TDNN.Classifier
  input_size: 192
  out_neurons: 7246


# FINETUNE: Wav2vec2 embedding + fc + ASP pooling + flatten + 1-2 layer dense + aam
# asp has to be in modules otherwise won't be put into gpu, then lead to 
# Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same
modules:
  compute_features: *id001
  mean_var_norm_emb: *id002
  embedding_model: &id015 !new:speechbrain.lobes.models.ECAPA_TDNN.ECAPA_TDNN
    input_size: 80
    channels: [1024, 1024, 1024, 1024, 3072]
    kernel_sizes: [5, 3, 3, 3, 1]
    dilations: [1, 2, 3, 4, 1]
    attention_channels: 128
    lin_neurons: 192



  fc1: *id003
  fc2: *id004
  dense1: *id005
  dense2: *id006
  output_mlp: *id007
  asp_pool: *id008
  bn_fc1: *id009
  bn_fc2: *id010
  bn_fc3: *id011
  batchnorm1: *id012
  batchnorm2: *id013
  batchnorm3: *id014
model: &id018 !new:torch.nn.ModuleList
- [*id015, *id003, *id004, *id008, *id005, *id006, *id009, *id012, *id010, *id013,
  *id011, *id014]
log_softmax: !new:speechbrain.nnet.activations.Softmax
  apply_log: true


compute_cost_nll: !name:speechbrain.nnet.losses.nll_loss


error_stats: !name:speechbrain.utils.metric_stats.MetricStats
  metric: !name:speechbrain.nnet.losses.classification_error
    reduction: batch

opt_class: !name:torch.optim.Adam
  lr: 0.00005
#     weight_decay: 0.000002
  weight_decay: 0.0001


# lr_annealing: !new:speechbrain.nnet.schedulers.NewBobScheduler
#     initial_value: !ref <lr>
#     improvement_threshold: 0.0025
#     annealing_factor: 0.8
#     patient: 0

lr_annealing: &id019 !new:speechbrain.nnet.schedulers.CyclicLRScheduler
#         lr_annealing_wav2vec2: !ref <lr_annealing_wav2vec2>
  base_lr: 0.00001
  max_lr: 0.00005
  step_size: 23430

label_encoder: &id017 !new:speechbrain.dataio.encoder.CategoricalEncoder

embedding_model: *id015
pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer
  loadables:
    embedding_model: *id015
    mean_var_norm_emb: *id002
    classifier: *id016
    label_encoder: *id017
  paths:
    embedding_model: speechbrain/spkrec-ecapa-voxceleb/embedding_model.ckpt
    mean_var_norm_emb: speechbrain/spkrec-ecapa-voxceleb/mean_var_norm_emb.ckpt
    classifier: speechbrain/spkrec-ecapa-voxceleb/classifier.ckpt
    label_encoder: speechbrain/spkrec-ecapa-voxceleb/label_encoder.txt



checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
  checkpoints_dir: /scratch/wc43/results/vox/1926/save_sm2_test
  recoverables:
    model: *id018
    embedding_model: *id015
    normalizer: *id002
    lr_annealing_output: *id019
    counter: *id020
